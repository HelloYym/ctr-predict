{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import load_pickle, dump_pickle, raw_data_path, feature_data_path\n",
    "\n",
    "from _2_2_gen_statistics_features import add_feature_click_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gap_before(s):\n",
    "    time_now, times = s.split('-')\n",
    "    times = times.split(':')\n",
    "    gaps = []\n",
    "    for t in times:\n",
    "        this_gap = int(time_now) - int(t)\n",
    "        if this_gap > 0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps) == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "\n",
    "\n",
    "def get_gap_after(s):\n",
    "    time_now, times = s.split('-')\n",
    "    times = times.split(':')\n",
    "    gaps = []\n",
    "    for t in times:\n",
    "        this_gap = int(t) - int(time_now)\n",
    "        if this_gap > 0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps) == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "\n",
    "\n",
    "def get_true_rank(s):\n",
    "    time_now, times = s.split('-')\n",
    "    times = times.split(':')\n",
    "    gaps = []\n",
    "    for t in times:\n",
    "        this_gap = int(time_now) - int(t)\n",
    "        if this_gap < 0:\n",
    "            gaps.append(this_gap)\n",
    "    return len(gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用户当前点击在一天中的排序\n",
    "        0: 只有一次点击\n",
    "        1: 第一次点击\n",
    "        2: 非首尾点击\n",
    "        3: 最后一次点击"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_day_rank_mapper(row):\n",
    "    '''\n",
    "\n",
    "    return:\n",
    "        0: 只有一次点击\n",
    "        1: 第一次点击\n",
    "        2: 非首尾点击\n",
    "        3: 最后一次点击\n",
    "\n",
    "    '''\n",
    "    if row['user_click_day'] <= 1:\n",
    "        return 0\n",
    "    elif row['user_first_click_day'] > 0:\n",
    "        return 1\n",
    "    elif row['user_last_click_day'] > 0:\n",
    "        return 3\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "def gen_user_click_rank_day(update=True):\n",
    "    '''生成用户当前点击在一天中的排序\n",
    "\n",
    "    file_name: user_click_day_rank.pkl\n",
    "\n",
    "    features:\n",
    "        'user_click_rank_day', \n",
    "        'user_first_click_day', \n",
    "        'user_last_click_day'\n",
    "\n",
    "    '''\n",
    "\n",
    "    data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "    feature_path = feature_data_path + 'user_click_rank_day.pkl'\n",
    "\n",
    "    if os.path.exists(feature_path) and update == False:\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        print('generating '+feature_path)\n",
    "\n",
    "        user_click_day = data.groupby(['user_id', 'day']).size(\n",
    "        ).reset_index().rename(columns={0: 'user_click_day'})\n",
    "\n",
    "        data = pd.merge(data, user_click_day, how='left',\n",
    "                        on=['user_id', 'day'])\n",
    "\n",
    "        instance = data.groupby(['instance_id']).size(\n",
    "        ).reset_index().rename(columns={0: 'instance_num'})\n",
    "\n",
    "        # 用户在一天内点击该物品的时间戳排序\n",
    "        sorted_data = data.sort_values(\n",
    "            by=['user_id', 'day', 'context_timestamp'], ascending=True)\n",
    "\n",
    "        # 保留一天内用户首次点击该物品的记录\n",
    "        first = sorted_data.drop_duplicates(['user_id', 'day']).copy()\n",
    "\n",
    "        # 保留一天内用户最后一次点击该物品的记录\n",
    "        last = sorted_data.drop_duplicates(\n",
    "            ['user_id', 'day'], keep='last').copy()\n",
    "\n",
    "        first['user_first_click_day'] = 1\n",
    "        first = first[['user_first_click_day']]\n",
    "        data = data.join(first)\n",
    "\n",
    "        last['user_last_click_day'] = 1\n",
    "        last = last[['user_last_click_day']]\n",
    "        data = data.join(last)\n",
    "\n",
    "        data[['user_first_click_day', 'user_last_click_day']] = data[[\n",
    "            'user_first_click_day', 'user_last_click_day']].fillna(0)\n",
    "\n",
    "        data['user_click_rank_day'] = data.apply(user_day_rank_mapper, axis=1)\n",
    "\n",
    "        data = data[['user_click_rank_day',\n",
    "                     'user_first_click_day', 'user_last_click_day']]\n",
    "        dump_pickle(data, feature_path)\n",
    "\n",
    "\n",
    "def add_user_click_rank_day(data):\n",
    "    '''添加用户当前点击在一天中的排序\n",
    "\n",
    "    join_key: ['instance_id',]\n",
    "\n",
    "    '''\n",
    "\n",
    "    feature_path = feature_data_path + 'user_click_rank_day.pkl'\n",
    "\n",
    "    if not os.path.exists(feature_path):\n",
    "        gen_user_click_rank_day()\n",
    "    user_click_rank_day = load_pickle(feature_path)\n",
    "    data = data.join(user_click_rank_day)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 添加用户当天点击的排名：user_click_true_rank_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_user_click_time_interval_day(update=True):\n",
    "    '''生成用户当前点击与当天首尾点击的时间间隔\n",
    "    \n",
    "    file_name: user_click_time_interval_day.pkl\n",
    "\n",
    "    features:\n",
    "        'user_click_interval_first_day', \n",
    "        'user_click_interval_last_day', \n",
    "        'user_click_true_rank_day', \n",
    "\n",
    "    '''\n",
    "\n",
    "    data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "    feature_path = feature_data_path + 'user_click_time_interval_day.pkl'\n",
    "\n",
    "    if os.path.exists(feature_path) and update == False:\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        print('generating '+feature_path)\n",
    "\n",
    "\n",
    "        # 用户在一天内点击该物品的时间戳排序\n",
    "        sorted_data = data.sort_values(\n",
    "            by=['user_id', 'day', 'context_timestamp'], ascending=True)\n",
    "\n",
    "        # 保留一天内用户首次点击该物品的记录\n",
    "        user_first_click_time_day = sorted_data.groupby(['user_id', 'day'])['context_timestamp'].first().reset_index().rename(columns={'context_timestamp': 'user_first_click_time_day'})\n",
    "        \n",
    "        # 保留一天内用户最后一次点击该物品的记录\n",
    "        user_last_click_time_day = sorted_data.groupby(['user_id', 'day'])['context_timestamp'].last().reset_index().rename(columns={'context_timestamp': 'user_last_click_time_day'})\n",
    "        \n",
    "        #保留一天内用户点击该物品的平均时间\n",
    "        user_mean_click_time_day = sorted_data.groupby(['user_id', 'day'])['context_timestamp'].mean().reset_index().rename(columns={'context_timestamp': 'user_mean_click_time_day'})\n",
    "\n",
    "        #计算一天内用户点击该物品时间的标准差\n",
    "        user_std_click_time_day = sorted_data.groupby(['user_id', 'day'])['context_timestamp'].std().reset_index().rename(columns={'context_timestamp': 'user_std_click_time_day'})\n",
    "        \n",
    "        data = pd.merge(data, user_first_click_time_day, 'left', on=['user_id', 'day'])\n",
    "        data = pd.merge(data, user_last_click_time_day, 'left', on=['user_id', 'day'])\n",
    "        data = pd.merge(data, user_mean_click_time_day, 'left', on=['user_id', 'day'])\n",
    "        data = pd.merge(data, user_std_click_time_day, 'left', on=['user_id', 'day'])\n",
    "        \n",
    "        data['user_click_interval_first_day'] = data['context_timestamp'] - data['user_first_click_time_day']\n",
    "        data['user_click_interval_last_day'] = data['user_last_click_time_day'] - data['context_timestamp']\n",
    "        data['user_click_interval_mean_day'] = data['context_timestamp'] - data['user_mean_click_time_day']\n",
    "        data['user_click_interval_diff_day'] = data['user_last_click_time_day'] - data['user_first_click_time_day']\n",
    "        data['user_click_interval_prob'] = data['user_click_interval_first_day'] / data['user_click_interval_diff_day']\n",
    "        \n",
    "        #计算当前点击时间与前一次后一次的时间差gap\n",
    "        t1 = data[['user_id', 'day', 'context_timestamp']]\n",
    "        t1.context_timestamp = t1.context_timestamp.astype('str')\n",
    "        t1 = t1.groupby(['user_id', 'day'])['context_timestamp'].agg(lambda x:':'.join(x)).reset_index()\n",
    "        t1.rename(columns={'context_timestamp':'times'},inplace=True)\n",
    "\n",
    "        t2 = data[['user_id', 'day', 'context_timestamp']]\n",
    "        t2 = pd.merge(t2, t1, on=['user_id', 'day'], how='left')\n",
    "        t2['time_now'] = t2.context_timestamp.astype('str') + '-' + t2.times\n",
    "        t2['time_gap_before'] = t2.time_now.apply(get_gap_before)\n",
    "        t2['time_gap_after'] = t2.time_now.apply(get_gap_after)\n",
    "        t2['user_click_true_rank_day'] = t2.time_now.apply(get_true_rank)\n",
    "        t3 = t2[['time_gap_before','time_gap_after', 'user_click_true_rank_day']]\n",
    "        \n",
    "        \n",
    "        data = data.join(t3)\n",
    "        \n",
    "        data = data[['user_click_interval_first_day', 'user_click_interval_last_day', \n",
    "                    'user_click_interval_diff_day','user_click_interval_prob',\n",
    "                     'time_gap_before','time_gap_after', 'user_click_true_rank_day']]\n",
    "        \n",
    "        dump_pickle(data, feature_path)\n",
    "\n",
    "\n",
    "def add_user_click_time_interval_day(data):\n",
    "    '''添加用户当前点击与当天首尾点击的时间间隔\n",
    "    \n",
    "    join_key: ['instance_id',]\n",
    "\n",
    "    '''\n",
    "\n",
    "    feature_path = feature_data_path + 'user_click_time_interval_day.pkl'\n",
    "\n",
    "    if not os.path.exists(feature_path):\n",
    "        gen_user_click_time_interval_day()\n",
    "        \n",
    "    user_click_interval_day = load_pickle(feature_path)\n",
    "    data = data.join(user_click_interval_day)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户全局点击的时间差特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_user_click_time_interval(update=True):\n",
    "    '''生成用户当前点击与当天首尾点击的时间间隔\n",
    "    \n",
    "    file_name: user_click_time_interval.pkl\n",
    "\n",
    "    features:\n",
    "\n",
    "    '''\n",
    "\n",
    "    data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "    feature_path = feature_data_path + 'user_click_time_interval.pkl'\n",
    "    \n",
    "\n",
    "    if os.path.exists(feature_path) and update == False:\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        print('generating '+feature_path)\n",
    "\n",
    "\n",
    "        # 用户点击该物品的时间戳排序，全局\n",
    "#         sorted_data = data.sort_values(\n",
    "#             by=['user_id', 'context_timestamp'], ascending=True)\n",
    "        \n",
    "        #保留一天内用户点击该物品的平均时间\n",
    "        user_mean_click_hour = data.groupby(['user_id',])['hour'].mean().reset_index().rename(columns={'hour': 'user_mean_click_hour'})\n",
    "        data = pd.merge(data, user_mean_click_hour, 'left', on=['user_id',])\n",
    "        data['user_click_interval_mean_hour'] = data['hour'] - data['user_mean_click_hour']\n",
    "        \n",
    "        #计算当前点击时间与前一次后一次的时间差gap\n",
    "        t1 = data[['user_id', 'context_timestamp']]\n",
    "        t1.context_timestamp = t1.context_timestamp.astype('str')\n",
    "        t1 = t1.groupby(['user_id', ])['context_timestamp'].agg(lambda x:':'.join(x)).reset_index()\n",
    "        t1.rename(columns={'context_timestamp':'times'},inplace=True)\n",
    "\n",
    "        t2 = data[['user_id', 'context_timestamp']]\n",
    "        t2 = pd.merge(t2, t1, on=['user_id', ], how='left')\n",
    "        t2['time_now'] = t2.context_timestamp.astype('str') + '-' + t2.times\n",
    "        t2['time_gap_before_total'] = t2.time_now.apply(get_gap_before)\n",
    "        t2['time_gap_after_total'] = t2.time_now.apply(get_gap_after)\n",
    "#         t2['user_click_true_rank_day'] = t2.time_now.apply(get_true_rank)\n",
    "        t3 = t2[['time_gap_before_total','time_gap_after_total',]]\n",
    "        \n",
    "        \n",
    "        data = data.join(t3)\n",
    "        \n",
    "        data = data[['user_click_interval_mean_hour', 'time_gap_before_total','time_gap_after_total',]]\n",
    "        \n",
    "        dump_pickle(data, feature_path)\n",
    "\n",
    "\n",
    "def add_user_click_time_interval(data):\n",
    "    '''添加用户当前点击与当天首尾点击的时间间隔\n",
    "    \n",
    "    join_key: ['instance_id',]\n",
    "\n",
    "    '''\n",
    "\n",
    "    feature_path = feature_data_path + 'user_click_time_interval.pkl'\n",
    "\n",
    "    if not os.path.exists(feature_path):\n",
    "        gen_user_click_time_interval()\n",
    "        \n",
    "    user_click_interval = load_pickle(feature_path)\n",
    "    data = data.join(user_click_interval)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全局：用户是第几次点击这个属性: 'user_' + feature + '_click_true_rank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_feature_rank_mapper(row):\n",
    "    '''\n",
    "\n",
    "    return:\n",
    "        0: 只有一次点击\n",
    "        1: 第一次点击\n",
    "        2: 非首尾点击\n",
    "        3: 最后一次点击\n",
    "\n",
    "    '''\n",
    "    if row['user_feature_click'] <= 1:\n",
    "        return 0\n",
    "    elif row['user_feature_first_click'] > 0:\n",
    "        return 1\n",
    "    elif row['user_feature_last_click'] > 0:\n",
    "        return 3\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "def gen_user_feature_click_rank(update=True):\n",
    "    '''用户是第几次点击这个属性\n",
    "\n",
    "    file_name: user_feature_click_rank.pkl\n",
    "\n",
    "    features:\n",
    "        'user_item_id_first_click', 'user_item_id_last_click',\n",
    "        'user_item_id_click_rank', 'user_item_id_first_click_interval',\n",
    "        'user_item_id_last_click_interval', 'user_item_brand_id_first_click',\n",
    "        'user_item_brand_id_last_click', 'user_item_brand_id_click_rank',\n",
    "        'user_item_brand_id_first_click_interval',\n",
    "        'user_item_brand_id_last_click_interval',\n",
    "        'user_item_city_id_first_click', 'user_item_city_id_last_click',\n",
    "        'user_item_city_id_click_rank',\n",
    "        'user_item_city_id_first_click_interval',\n",
    "        'user_item_city_id_last_click_interval', 'user_shop_id_first_click',\n",
    "        'user_shop_id_last_click', 'user_shop_id_click_rank',\n",
    "        'user_shop_id_first_click_interval',\n",
    "        'user_shop_id_last_click_interval'\n",
    "\n",
    "    '''\n",
    "\n",
    "    all_data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "    feature_path = feature_data_path + 'user_feature_click_rank.pkl'\n",
    "\n",
    "    feature_list = ['item_id', 'item_brand_id', 'shop_id', 'context_page_id', 'category2_label',]\n",
    "\n",
    "    for feature in tqdm(feature_list):\n",
    "\n",
    "        feature_path = feature_data_path + 'user_'+feature+'_click_rank.pkl'\n",
    "\n",
    "        if os.path.exists(feature_path) and update == False:\n",
    "            print('found '+feature_path)\n",
    "        else:\n",
    "            print('generating '+feature_path)\n",
    "\n",
    "            first_click_feature_name = 'user_' + feature + '_first_click'\n",
    "            last_click_feature_name = 'user_' + feature + '_last_click'\n",
    "            rank_feature_name = 'user_' + feature + '_click_rank'\n",
    "            \n",
    "            true_rank_feature_name = 'user_' + feature + '_click_true_rank'\n",
    "            \n",
    "            first_click_time_name = 'user_' + feature + '_first_click_time'\n",
    "            last_click_time_name = 'user_' + feature + '_last_click_time'\n",
    "            first_click_interval_name = 'user_' + feature + '_first_click_interval'\n",
    "            last_click_interval_name = 'user_' + feature + '_last_click_interval'\n",
    "            \n",
    "            mean_click_time_name = 'user_' + feature + '_mean_click_time'\n",
    "            std_click_time_name = 'user_' + feature + '_std_click_time'\n",
    "            mean_click_interval_name = 'user_' + feature + '_mean_click_interval'\n",
    "            diff_click_interval_name = 'user_' + feature + '_diff_click_interval'\n",
    "            prob_click_interval_name = 'user_' + feature + '_prob_click_interval'\n",
    "            \n",
    "            time_gap_before_name = feature + '_time_gap_before'\n",
    "            time_gap_after_name = feature + '_time_gap_after'\n",
    "            \n",
    "            \n",
    "            user_feature_click = all_data.groupby(['user_id', feature]).size(\n",
    "            ).reset_index().rename(columns={0: 'user_feature_click'})\n",
    "\n",
    "            data = pd.merge(all_data, user_feature_click,\n",
    "                            how='left', on=['user_id', feature])\n",
    "\n",
    "            # 用户在一天内点击该物品的时间戳排序\n",
    "            sorted_data = data.sort_values(\n",
    "                by=['user_id', feature, 'context_timestamp'], ascending=True)[['user_id', feature, 'context_timestamp']]\n",
    "\n",
    "            #保留一天内用户点击该物品的平均时间\n",
    "            user_mean_click_time_feature = sorted_data.groupby(['user_id', feature])['context_timestamp'].mean().reset_index().rename(columns={'context_timestamp': mean_click_time_name})\n",
    "            #计算一天内用户点击该物品时间的标准差\n",
    "            user_std_click_time_feature = sorted_data.groupby(['user_id', feature])['context_timestamp'].std().reset_index().rename(columns={'context_timestamp': std_click_time_name})\n",
    "            \n",
    "            # 保留一天内用户首次点击该物品的记录\n",
    "            first = sorted_data.drop_duplicates(['user_id', feature]).copy()\n",
    "\n",
    "            # 保留一天内用户最后一次点击该物品的记录\n",
    "            last = sorted_data.drop_duplicates(\n",
    "                ['user_id', feature], keep='last').copy()\n",
    "\n",
    "            first.rename(columns = {'context_timestamp': first_click_time_name}, inplace=True)\n",
    "            last.rename(columns = {'context_timestamp': last_click_time_name}, inplace=True)\n",
    "\n",
    "            data = pd.merge(data, first, 'left', on=['user_id', feature])\n",
    "            data = pd.merge(data, last, 'left', on=['user_id', feature])\n",
    "            data = pd.merge(data, user_mean_click_time_feature, 'left', on=['user_id', feature])\n",
    "            data = pd.merge(data, user_std_click_time_feature, 'left', on=['user_id', feature])\n",
    "            \n",
    "\n",
    "            data[first_click_interval_name] = data['context_timestamp'] -  data[first_click_time_name]\n",
    "            data[last_click_interval_name] = data[last_click_time_name] -  data['context_timestamp']\n",
    "            data[mean_click_interval_name] = data['context_timestamp'] -  data[mean_click_time_name]\n",
    "            data[diff_click_interval_name] = data[last_click_time_name] -  data[first_click_time_name]\n",
    "            data[prob_click_interval_name] = data[first_click_interval_name] / data[diff_click_interval_name]\n",
    "            \n",
    "            first['user_feature_first_click'] = 1\n",
    "            first = first[['user_feature_first_click']]\n",
    "            data = data.join(first)\n",
    "\n",
    "            last['user_feature_last_click'] = 1\n",
    "            last = last[['user_feature_last_click']]\n",
    "            data = data.join(last)\n",
    "\n",
    "            data[['user_feature_first_click', 'user_feature_last_click']] = data[[\n",
    "                'user_feature_first_click', 'user_feature_last_click']].fillna(0)\n",
    "\n",
    "            data['user_feature_click_rank'] = data.apply(user_feature_rank_mapper, axis=1)\n",
    "\n",
    "            data.rename(columns={'user_feature_first_click': first_click_feature_name, 'user_feature_last_click': last_click_feature_name,\n",
    "                                 'user_feature_click_rank': rank_feature_name}, inplace=True)\n",
    "            \n",
    "            \n",
    "            #计算当前点击时间与前一次后一次的时间差gap\n",
    "            t1 = all_data[['user_id', feature, 'context_timestamp']]\n",
    "            t1.context_timestamp = t1.context_timestamp.astype('str')\n",
    "            t1 = t1.groupby(['user_id', feature])['context_timestamp'].agg(lambda x:':'.join(x)).reset_index()\n",
    "            t1.rename(columns={'context_timestamp':'times'},inplace=True)\n",
    "\n",
    "            t2 = all_data[['user_id', feature, 'context_timestamp']]\n",
    "            t2 = pd.merge(t2, t1, on=['user_id', feature], how='left')\n",
    "            t2['time_now'] = t2.context_timestamp.astype('str') + '-' + t2.times\n",
    "            t2[time_gap_before_name] = t2.time_now.apply(get_gap_before)\n",
    "            t2[time_gap_after_name] = t2.time_now.apply(get_gap_after)\n",
    "            t2[true_rank_feature_name] = t2.time_now.apply(get_true_rank)\n",
    "            t3 = t2[[time_gap_before_name,time_gap_after_name, true_rank_feature_name]]\n",
    "        \n",
    "            data = data.join(t3)\n",
    "            \n",
    "            data = data[[first_click_feature_name, last_click_feature_name,\n",
    "                         rank_feature_name, first_click_interval_name, last_click_interval_name,\n",
    "                        diff_click_interval_name, prob_click_interval_name,\n",
    "                        time_gap_before_name,time_gap_after_name,\n",
    "                        true_rank_feature_name]]\n",
    "            dump_pickle(data, feature_path)\n",
    "\n",
    "\n",
    "def add_user_feature_click_rank(data):\n",
    "    '''添加用户当前点击在一天中的排序\n",
    "\n",
    "    join_key: ['instance_id',]\n",
    "\n",
    "    '''\n",
    "\n",
    "    feature_list = ['item_id', 'item_brand_id', 'shop_id', 'context_page_id', 'category2_label',]\n",
    "\n",
    "    for feature in tqdm(feature_list):\n",
    "        feature_path = feature_data_path + 'user_'+feature+'_click_rank.pkl'\n",
    "        if not os.path.exists(feature_path):\n",
    "            gen_user_feature_click_rank()\n",
    "        user_feature_click_rank = load_pickle(feature_path)\n",
    "        data = data.join(user_feature_click_rank)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 当天：用户是第几次点击这个属性: 'user_' + feature + '_click_true_rank_day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_feature_rank_day_mapper(row):\n",
    "    '''\n",
    "\n",
    "    return:\n",
    "        0: 只有一次点击\n",
    "        1: 第一次点击\n",
    "        2: 非首尾点击\n",
    "        3: 最后一次点击\n",
    "\n",
    "    '''\n",
    "    if row['user_feature_click_day'] <= 1:\n",
    "        return 0\n",
    "    elif row['user_feature_first_click_day'] > 0:\n",
    "        return 1\n",
    "    elif row['user_feature_last_click_day'] > 0:\n",
    "        return 3\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "def gen_user_feature_click_rank_day(update=True):\n",
    "    '''用户是第几次点击这个属性\n",
    "\n",
    "    file_name: user_feature_click_rank_day.pkl\n",
    "\n",
    "    features:\n",
    "        'user_item_id_first_click', 'user_item_id_last_click',\n",
    "        'user_item_id_click_rank', 'user_item_id_first_click_interval',\n",
    "        'user_item_id_last_click_interval', 'user_item_brand_id_first_click',\n",
    "        'user_item_brand_id_last_click', 'user_item_brand_id_click_rank',\n",
    "        'user_item_brand_id_first_click_interval',\n",
    "        'user_item_brand_id_last_click_interval',\n",
    "        'user_item_city_id_first_click', 'user_item_city_id_last_click',\n",
    "        'user_item_city_id_click_rank',\n",
    "        'user_item_city_id_first_click_interval',\n",
    "        'user_item_city_id_last_click_interval', 'user_shop_id_first_click',\n",
    "        'user_shop_id_last_click', 'user_shop_id_click_rank',\n",
    "        'user_shop_id_first_click_interval',\n",
    "        'user_shop_id_last_click_interval'\n",
    "\n",
    "    '''\n",
    "\n",
    "    all_data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "#     feature_path = feature_data_path + 'user_feature_click_rank_day.pkl'\n",
    "\n",
    "    feature_list = ['item_id', 'item_brand_id',\n",
    "                    'shop_id', 'context_page_id', 'category2_label', ]\n",
    "\n",
    "    for feature in tqdm(feature_list):\n",
    "\n",
    "        feature_path = feature_data_path + 'user_'+feature + '_click_rank_day.pkl'\n",
    "\n",
    "        if os.path.exists(feature_path) and update == False:\n",
    "            print('found '+feature_path)\n",
    "        else:\n",
    "            print('generating '+feature_path)\n",
    "\n",
    "            first_click_feature_name = 'user_' + feature + '_first_click_day'\n",
    "            last_click_feature_name = 'user_' + feature + '_last_click_day'\n",
    "            rank_feature_name = 'user_' + feature + '_click_rank_day'\n",
    "\n",
    "            true_rank_feature_name = 'user_' + feature + '_click_true_rank_day'\n",
    "\n",
    "            first_click_time_name = 'user_' + feature + '_first_click_time_day'\n",
    "            last_click_time_name = 'user_' + feature + '_last_click_time_day'\n",
    "            first_click_interval_name = 'user_' + feature + '_first_click_interval_day'\n",
    "            last_click_interval_name = 'user_' + feature + '_last_click_interval_day'\n",
    "\n",
    "            mean_click_time_name = 'user_' + feature + '_mean_click_time_day'\n",
    "            std_click_time_name = 'user_' + feature + '_std_click_time_day'\n",
    "            mean_click_interval_name = 'user_' + feature + '_mean_click_interval_day'\n",
    "            diff_click_interval_name = 'user_' + feature + '_diff_click_interval_day'\n",
    "            prob_click_interval_name = 'user_' + feature + '_prob_click_interval_day'\n",
    "\n",
    "            time_gap_before_name = feature + '_time_gap_before_day'\n",
    "            time_gap_after_name = feature + '_time_gap_after_day'\n",
    "\n",
    "            user_feature_click_day = all_data.groupby(['user_id', feature, 'day']).size(\n",
    "            ).reset_index().rename(columns={0: 'user_feature_click_day'})\n",
    "\n",
    "            data = pd.merge(all_data, user_feature_click_day,\n",
    "                            how='left', on=['user_id', feature, 'day'])\n",
    "\n",
    "            # 用户在一天内点击该物品的时间戳排序\n",
    "            sorted_data = data.sort_values(\n",
    "                by=['user_id', feature, 'day', 'context_timestamp'], ascending=True)[['user_id', feature, 'day', 'context_timestamp']]\n",
    "\n",
    "            # 保留一天内用户点击该物品的平均时间\n",
    "            user_mean_click_time_feature = sorted_data.groupby(['user_id', feature, 'day'])['context_timestamp'].mean(\n",
    "            ).reset_index().rename(columns={'context_timestamp': mean_click_time_name})\n",
    "            # 计算一天内用户点击该物品时间的标准差\n",
    "            user_std_click_time_feature = sorted_data.groupby(['user_id', feature, 'day'])['context_timestamp'].std(\n",
    "            ).reset_index().rename(columns={'context_timestamp': std_click_time_name})\n",
    "\n",
    "            # 保留一天内用户首次点击该物品的记录\n",
    "            first = sorted_data.drop_duplicates(['user_id', feature, 'day']).copy()\n",
    "\n",
    "            # 保留一天内用户最后一次点击该物品的记录\n",
    "            last = sorted_data.drop_duplicates(\n",
    "                ['user_id', feature, 'day'], keep='last').copy()\n",
    "\n",
    "            first.rename(\n",
    "                columns={'context_timestamp': first_click_time_name}, inplace=True)\n",
    "            last.rename(\n",
    "                columns={'context_timestamp': last_click_time_name}, inplace=True)\n",
    "\n",
    "            data = pd.merge(data, first, 'left', on=['user_id', feature, 'day'])\n",
    "            data = pd.merge(data, last, 'left', on=['user_id', feature, 'day'])\n",
    "            data = pd.merge(data, user_mean_click_time_feature,\n",
    "                            'left', on=['user_id', feature, 'day'])\n",
    "            data = pd.merge(data, user_std_click_time_feature,\n",
    "                            'left', on=['user_id', feature, 'day'])\n",
    "\n",
    "            data[first_click_interval_name] = data['context_timestamp'] - \\\n",
    "                data[first_click_time_name]\n",
    "            data[last_click_interval_name] = data[last_click_time_name] - \\\n",
    "                data['context_timestamp']\n",
    "            data[mean_click_interval_name] = data['context_timestamp'] - \\\n",
    "                data[mean_click_time_name]\n",
    "            data[diff_click_interval_name] = data[last_click_time_name] - \\\n",
    "                data[first_click_time_name]\n",
    "            data[prob_click_interval_name] = data[first_click_interval_name] / \\\n",
    "                data[diff_click_interval_name]\n",
    "\n",
    "            first['user_feature_first_click_day'] = 1\n",
    "            first = first[['user_feature_first_click_day']]\n",
    "            data = data.join(first)\n",
    "\n",
    "            last['user_feature_last_click_day'] = 1\n",
    "            last = last[['user_feature_last_click_day']]\n",
    "            data = data.join(last)\n",
    "\n",
    "            data[['user_feature_first_click_day', 'user_feature_last_click_day']] = data[[\n",
    "                'user_feature_first_click_day', 'user_feature_last_click_day']].fillna(0)\n",
    "\n",
    "            data['user_feature_click_rank_day'] = data.apply(\n",
    "                user_feature_rank_day_mapper, axis=1)\n",
    "\n",
    "            data.rename(columns={'user_feature_first_click_day': first_click_feature_name, 'user_feature_last_click_day': last_click_feature_name,\n",
    "                                 'user_feature_click_rank_day': rank_feature_name}, inplace=True)\n",
    "\n",
    "            # 计算当前点击时间与前一次后一次的时间差gap\n",
    "            t1 = all_data[['user_id', 'day', feature, 'context_timestamp']]\n",
    "            t1.context_timestamp = t1.context_timestamp.astype('str')\n",
    "            t1 = t1.groupby(['user_id', feature, 'day'])['context_timestamp'].agg(\n",
    "                lambda x: ':'.join(x)).reset_index()\n",
    "            t1.rename(columns={'context_timestamp': 'times'}, inplace=True)\n",
    "\n",
    "            t2 = all_data[['user_id', 'day', feature, 'context_timestamp']]\n",
    "            t2 = pd.merge(t2, t1, on=['user_id', feature, 'day'], how='left')\n",
    "            t2['time_now'] = t2.context_timestamp.astype(\n",
    "                'str') + '-' + t2.times\n",
    "            t2[time_gap_before_name] = t2.time_now.apply(get_gap_before)\n",
    "            t2[time_gap_after_name] = t2.time_now.apply(get_gap_after)\n",
    "            t2[true_rank_feature_name] = t2.time_now.apply(get_true_rank)\n",
    "            t3 = t2[[time_gap_before_name,\n",
    "                     time_gap_after_name, true_rank_feature_name]]\n",
    "\n",
    "            data = data.join(t3)\n",
    "\n",
    "            data = data[[first_click_feature_name, last_click_feature_name,\n",
    "                         rank_feature_name, first_click_interval_name, last_click_interval_name,\n",
    "                         diff_click_interval_name, prob_click_interval_name,\n",
    "                         time_gap_before_name, time_gap_after_name,\n",
    "                         true_rank_feature_name]]\n",
    "            \n",
    "            dump_pickle(data, feature_path)\n",
    "\n",
    "\n",
    "def add_user_feature_click_rank_day(data):\n",
    "    '''添加用户当前点击在一天中的排序\n",
    "\n",
    "    join_key: ['instance_id',]\n",
    "\n",
    "    '''\n",
    "\n",
    "    feature_list = ['item_id', 'item_brand_id',\n",
    "                    'shop_id', 'context_page_id', 'category2_label', ]\n",
    "\n",
    "    for feature in tqdm(feature_list):\n",
    "        feature_path = feature_data_path + 'user_'+feature+'_click_rank_day.pkl'\n",
    "        if not os.path.exists(feature_path):\n",
    "            gen_user_feature_click_rank_day()\n",
    "        user_feature_click_rank_day = load_pickle(feature_path)\n",
    "        data = data.join(user_feature_click_rank_day)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user click interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_click_rank_day.pkl\n",
      "generating ../features/user_click_time_interval_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user02/miniconda3/envs/gluon/lib/python3.6/site-packages/pandas/core/generic.py:3110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_click_time_interval.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_item_id_click_rank.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:25<01:43, 25.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_item_brand_id_click_rank.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 2/5 [00:51<01:17, 25.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_shop_id_click_rank.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [01:16<00:51, 25.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_context_page_id_click_rank.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 4/5 [01:43<00:25, 25.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_category2_label_click_rank.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [02:10<00:00, 26.38s/it]\u001b[A\n",
      "100%|██████████| 5/5 [02:11<00:00, 31.60s/it] \n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_item_id_click_rank_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:25<01:40, 25.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_item_brand_id_click_rank_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 2/5 [00:50<01:15, 25.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_shop_id_click_rank_day.pkl\n"
     ]
    }
   ],
   "source": [
    "if __name__ =='__main__':\n",
    "    all_data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "    \n",
    "    all_data = add_user_click_rank_day(all_data)\n",
    "    all_data = add_user_click_time_interval_day(all_data)\n",
    "    all_data = add_user_click_time_interval(all_data)\n",
    "    \n",
    "    all_data = add_user_feature_click_rank(all_data)\n",
    "    all_data = add_user_feature_click_rank_day(all_data)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 想要添加：\n",
    "    该次点击是用户第几次访问这个物品，全局数据"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
