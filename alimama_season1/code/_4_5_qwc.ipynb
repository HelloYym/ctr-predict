{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import time\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import load_pickle, dump_pickle, get_feature_value, feature_spearmanr, feature_target_spearmanr, addCrossFeature, calibration\n",
    "from utils import raw_data_path, feature_data_path, cache_pkl_path, analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_path = feature_data_path + 'all_data_all_features.pkl'\n",
    "all_data = load_pickle(all_data_path)\n",
    "\n",
    "target = 'is_trade'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    # 预处理后的基础特征----------------------------------------------\n",
    "#     'instance_id',\n",
    "     'item_id',\n",
    "     'item_brand_id',\n",
    "     'item_city_id',\n",
    "     'item_price_level',\n",
    "     'item_sales_level',\n",
    "     'item_collected_level',\n",
    "     'item_pv_level',\n",
    "     'user_id',\n",
    "     'user_gender_id',\n",
    "     'user_age_level',\n",
    "     'user_occupation_id',\n",
    "     'user_star_level',\n",
    "     'context_id',\n",
    "     'context_timestamp',\n",
    "     'context_page_id',\n",
    "     'shop_id',\n",
    "     'shop_review_num_level',\n",
    "     'shop_review_positive_rate',\n",
    "     'shop_star_level',\n",
    "     'shop_score_service',\n",
    "     'shop_score_delivery',\n",
    "     'shop_score_description',\n",
    "#     'is_trade',\n",
    "     'day',\n",
    "     'hour',\n",
    "#     'minute',\n",
    "     'category2_label',\n",
    "     'item_property_list0',\n",
    "     'item_property_list1',\n",
    "     'item_property_list2',\n",
    "     'item_property_list3',\n",
    "     'item_property_list4',\n",
    "     'item_property_list5',\n",
    "     'item_property_list6',\n",
    "     'item_property_list7',\n",
    "    #  2_1处理后的特征\n",
    "    #  生成用户对当天属性的点击量\n",
    "    #     ['item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level',\n",
    "    #     'item_collected_level', 'item_pv_level',\n",
    "    #     'context_page_id',\n",
    "    #     'shop_id', 'shop_review_num_level', 'shop_star_level',]\n",
    "     'user_item_id_click_day',\n",
    "     'user_item_brand_id_click_day',\n",
    "#     'user_item_city_id_click_day',\n",
    "     'user_category2_label_click_day',\n",
    "     'user_item_price_level_click_day',\n",
    "     'user_item_sales_level_click_day',\n",
    "#     'user_item_collected_level_click_day',\n",
    "#     'user_item_pv_level_click_day',\n",
    "     'user_context_page_id_click_day',\n",
    "     'user_shop_id_click_day',\n",
    "#     'user_shop_review_num_level_click_day',\n",
    "#     'user_shop_star_level_click_day',\n",
    "    \n",
    "    #  2_5处理后的特征\n",
    "    #  user_id前一天点击某某某的数量\n",
    "    #  ['item_id', 'item_brand_id', 'shop_id', 'category2_label',]\n",
    "     'user_id_item_id_day_I',\n",
    "     'user_id_item_id_day_C',\n",
    "     'user_id_item_brand_id_day_I',\n",
    "     'user_id_item_brand_id_day_C',\n",
    "     'user_id_shop_id_day_I',\n",
    "     'user_id_shop_id_day_C',\n",
    "     'user_id_category2_label_day_I',\n",
    "     'user_id_category2_label_day_C',\n",
    "     'user_id_item_price_level_day_I',\n",
    "     'user_id_item_price_level_day_C',\n",
    "    #  2_5处理后的特征\n",
    "    #  user_id历史点击某某某的数量\n",
    "    #  ['item_id', 'item_brand_id', 'shop_id', 'category2_label',]\n",
    "     'user_id_item_id_history_I',\n",
    "     'user_id_item_id_history_C',\n",
    "     'user_id_item_brand_id_history_I',\n",
    "     'user_id_item_brand_id_history_C',\n",
    "     'user_id_shop_id_history_I',\n",
    "     'user_id_shop_id_history_C',\n",
    "     'user_id_category2_label_history_I',\n",
    "     'user_id_category2_label_history_C',\n",
    "     'user_id_item_price_level_history_I',\n",
    "     'user_id_item_price_level_history_C',\n",
    "    \n",
    "    #  2_1处理后的特征\n",
    "    #  生成用户对当天当小时属性的点击量\n",
    "    #     ['item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level',\n",
    "    #     'item_collected_level', 'item_pv_level',\n",
    "    #     'context_page_id',\n",
    "    #     'shop_id', 'shop_review_num_level', 'shop_star_level',]\n",
    "     'user_item_id_click_hour',\n",
    "     'user_item_brand_id_click_hour',\n",
    "#     'user_item_city_id_click_hour',\n",
    "     'user_category2_label_click_hour',\n",
    "     'user_item_price_level_click_hour',\n",
    "     'user_item_sales_level_click_hour',\n",
    "#     'user_item_collected_level_click_hour',\n",
    "#     'user_item_pv_level_click_hour',\n",
    "     'user_context_page_id_click_hour',\n",
    "     'user_shop_id_click_hour',\n",
    "#     'user_shop_review_num_level_click_hour',\n",
    "#     'user_shop_star_level_click_hour',\n",
    "    #  2_1处理后的特征\n",
    "    #  生成用户对单一特征点击数据的统计特征\n",
    "     'user_item_id_click_day_mean',\n",
    "     'user_item_id_click_day_min',\n",
    "     'user_item_id_click_day_max',\n",
    "     'user_item_brand_id_click_day_mean',\n",
    "     'user_item_brand_id_click_day_min',\n",
    "     'user_item_brand_id_click_day_max',\n",
    "     'user_shop_id_click_day_mean',\n",
    "     'user_shop_id_click_day_min',\n",
    "     'user_shop_id_click_day_max',\n",
    "     'user_category2_label_click_day_mean',\n",
    "     'user_category2_label_click_day_min',\n",
    "     'user_category2_label_click_day_max',\n",
    "    \n",
    "    #  2_2处理后的特征\n",
    "    #  生成单一特征，日点击量的统计特征    stats_feature = ['user_id', 'item_id', 'item_brand_id', 'shop_id']\n",
    "     'user_id_click_day_mean',\n",
    "     'user_id_click_day_max',\n",
    "     'user_id_click_day_min',\n",
    "     'item_id_click_day_mean',\n",
    "     'item_id_click_day_max',\n",
    "     'item_id_click_day_min',\n",
    "     'item_brand_id_click_day_mean',\n",
    "     'item_brand_id_click_day_max',\n",
    "     'item_brand_id_click_day_min',\n",
    "     'shop_id_click_day_mean',\n",
    "     'shop_id_click_day_max',\n",
    "     'shop_id_click_day_min',\n",
    "    \n",
    "    #  2_3处理后的特征\n",
    "    #  生成用户日点击时间差特征\n",
    "     'user_click_rank_day',\n",
    "#     'user_first_click_day',\n",
    "#     'user_last_click_day',\n",
    "     'user_click_interval_first_day',\n",
    "     'user_click_interval_last_day',\n",
    "#     'user_click_interval_diff_day',\n",
    "#     'user_click_interval_prob',\n",
    "     'time_gap_before',\n",
    "     'time_gap_after',\n",
    "     'user_click_true_rank_day',\n",
    "    #  2_3处理后的特征\n",
    "    #  生成用户全局击时间差特征\n",
    "     'user_click_interval_mean_hour',\n",
    "     'time_gap_before_total',\n",
    "     'time_gap_after_total',\n",
    "    #  2_3处理后的特征\n",
    "    #  生成用户对属性全局点击时间差特征\n",
    "    #   ['item_id', 'item_brand_id', 'shop_id', 'context_page_id', 'category2_label',]    \n",
    "#     'user_item_id_first_click',\n",
    "#     'user_item_id_last_click',\n",
    "#     'user_item_id_click_rank',\n",
    "     'user_item_id_first_click_interval',\n",
    "     'user_item_id_last_click_interval',\n",
    "#     'user_item_id_diff_click_interval',\n",
    "#     'user_item_id_prob_click_interval',\n",
    "     'item_id_time_gap_before',\n",
    "     'item_id_time_gap_after',\n",
    "#     'user_item_id_click_true_rank',\n",
    "#     'user_item_brand_id_first_click',\n",
    "#     'user_item_brand_id_last_click',\n",
    "#     'user_item_brand_id_click_rank',\n",
    "     'user_item_brand_id_first_click_interval',\n",
    "     'user_item_brand_id_last_click_interval',\n",
    "#     'user_item_brand_id_diff_click_interval',\n",
    "#     'user_item_brand_id_prob_click_interval',\n",
    "     'item_brand_id_time_gap_before',\n",
    "     'item_brand_id_time_gap_after',\n",
    "#     'user_item_brand_id_click_true_rank',\n",
    "#     'user_shop_id_first_click',\n",
    "#     'user_shop_id_last_click',\n",
    "#     'user_shop_id_click_rank',\n",
    "     'user_shop_id_first_click_interval',\n",
    "     'user_shop_id_last_click_interval',\n",
    "#     'user_shop_id_diff_click_interval',\n",
    "#     'user_shop_id_prob_click_interval',\n",
    "     'shop_id_time_gap_before',\n",
    "     'shop_id_time_gap_after',\n",
    "#     'user_shop_id_click_true_rank',\n",
    "#      'user_context_page_id_first_click',\n",
    "#      'user_context_page_id_last_click',\n",
    "#      'user_context_page_id_click_rank',\n",
    "#      'user_context_page_id_first_click_interval',\n",
    "#      'user_context_page_id_last_click_interval',\n",
    "# #     'user_context_page_id_diff_click_interval',\n",
    "# #     'user_context_page_id_prob_click_interval',\n",
    "#      'context_page_id_time_gap_before',\n",
    "#      'context_page_id_time_gap_after',\n",
    "#      'user_context_page_id_click_true_rank',\n",
    "#     'user_category2_label_first_click',\n",
    "#     'user_category2_label_last_click',\n",
    "#     'user_category2_label_click_rank',\n",
    "     'user_category2_label_first_click_interval',\n",
    "     'user_category2_label_last_click_interval',\n",
    "#     'user_category2_label_diff_click_interval',\n",
    "#     'user_category2_label_prob_click_interval',\n",
    "     'category2_label_time_gap_before',\n",
    "     'category2_label_time_gap_after',\n",
    "#     'user_category2_label_click_true_rank',\n",
    "    #  2_3处理后的特征\n",
    "    #  生成用户对属性当天点击时间差特征\n",
    "    #   ['item_id', 'item_brand_id', 'shop_id', 'context_page_id', 'category2_label',]    \n",
    "#     'user_item_id_first_click_day',\n",
    "#     'user_item_id_last_click_day',\n",
    "     'user_item_id_click_rank_day',\n",
    "     'user_item_id_first_click_interval_day',\n",
    "     'user_item_id_last_click_interval_day',\n",
    "#     'user_item_id_diff_click_interval_day',\n",
    "#     'user_item_id_prob_click_interval_day',\n",
    "     'item_id_time_gap_before_day',\n",
    "     'item_id_time_gap_after_day',\n",
    "     'user_item_id_click_true_rank_day',\n",
    "#     'user_item_brand_id_first_click_day',\n",
    "#     'user_item_brand_id_last_click_day',\n",
    "     'user_item_brand_id_click_rank_day',\n",
    "     'user_item_brand_id_first_click_interval_day',\n",
    "     'user_item_brand_id_last_click_interval_day',\n",
    "#     'user_item_brand_id_diff_click_interval_day',\n",
    "#     'user_item_brand_id_prob_click_interval_day',\n",
    "     'item_brand_id_time_gap_before_day',\n",
    "     'item_brand_id_time_gap_after_day',\n",
    "     'user_item_brand_id_click_true_rank_day',\n",
    "#     'user_shop_id_first_click_day',\n",
    "#     'user_shop_id_last_click_day',\n",
    "     'user_shop_id_click_rank_day',\n",
    "     'user_shop_id_first_click_interval_day',\n",
    "     'user_shop_id_last_click_interval_day',\n",
    "#     'user_shop_id_diff_click_interval_day',\n",
    "#     'user_shop_id_prob_click_interval_day',\n",
    "     'shop_id_time_gap_before_day',\n",
    "     'shop_id_time_gap_after_day',\n",
    "     'user_shop_id_click_true_rank_day',\n",
    "#      'user_context_page_id_first_click_day',\n",
    "#      'user_context_page_id_last_click_day',\n",
    "#      'user_context_page_id_click_rank_day',\n",
    "#      'user_context_page_id_first_click_interval_day',\n",
    "#      'user_context_page_id_last_click_interval_day',\n",
    "# #     'user_context_page_id_diff_click_interval_day',\n",
    "# #     'user_context_page_id_prob_click_interval_day',\n",
    "#      'context_page_id_time_gap_before_day',\n",
    "#      'context_page_id_time_gap_after_day',\n",
    "#      'user_context_page_id_click_true_rank_day',\n",
    "#     'user_category2_label_first_click_day',\n",
    "#     'user_category2_label_last_click_day',\n",
    "     'user_category2_label_click_rank_day',\n",
    "     'user_category2_label_first_click_interval_day',\n",
    "     'user_category2_label_last_click_interval_day',\n",
    "#     'user_category2_label_diff_click_interval_day',\n",
    "#     'user_category2_label_prob_click_interval_day',\n",
    "     'category2_label_time_gap_before_day',\n",
    "     'category2_label_time_gap_after_day',\n",
    "     'user_category2_label_click_true_rank_day',\n",
    "    \n",
    "    #  2_4处理后的特征\n",
    "     'property_sim',\n",
    "     'category_predict_rank',\n",
    "     'category_3',\n",
    "    \n",
    "    #  2_5处理后的特征\n",
    "    #  生成单特征历史点击率，要去除点击次数和点击时间\n",
    "    #     ['user_id', 'category_predict_rank', 'user_occupation_id', 'user_age_level', 'user_gender_id', 'user_star_level',\n",
    "    #     'item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level',\n",
    "    #     'item_collected_level', 'item_pv_level',\n",
    "    #     'context_page_id',\n",
    "    #     'shop_id', 'shop_review_num_level', 'shop_star_level',]    \n",
    "     'user_id_smooth_CTR',\n",
    "     'category_predict_rank_smooth_CTR',\n",
    "     'user_occupation_id_smooth_CTR',\n",
    "     'user_age_level_smooth_CTR',\n",
    "     'user_gender_id_smooth_CTR',\n",
    "     'user_star_level_smooth_CTR',\n",
    "     'item_id_smooth_CTR',\n",
    "     'item_brand_id_smooth_CTR',\n",
    "#     'item_city_id_smooth_CTR',\n",
    "     'category2_label_smooth_CTR',\n",
    "     'item_price_level_smooth_CTR',\n",
    "     'item_sales_level_smooth_CTR',\n",
    "     'item_collected_level_smooth_CTR',\n",
    "#     'item_pv_level_smooth_CTR',\n",
    "     'context_page_id_smooth_CTR',\n",
    "     'shop_id_smooth_CTR',\n",
    "#     'shop_review_num_level_smooth_CTR',\n",
    "#     'shop_star_level_smooth_CTR',\n",
    "    #  2_5处理后的特征\n",
    "    #  生成单特征前一天点击率，前一天的点击次数，前一天的购买次数， 去除ctr\n",
    "    #     ['user_id', 'category_predict_rank', 'user_occupation_id', 'user_age_level', 'user_gender_id', 'user_star_level',\n",
    "    #     'item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level',\n",
    "    #     'item_collected_level', 'item_pv_level',\n",
    "    #     'context_page_id',\n",
    "    #     'shop_id', 'shop_review_num_level', 'shop_star_level',]\n",
    "     'user_id_day_I',\n",
    "     'user_id_day_C',\n",
    "#     'category_predict_rank_day_I',\n",
    "#     'category_predict_rank_day_C',\n",
    "#     'user_occupation_id_day_I',\n",
    "#     'user_occupation_id_day_C',\n",
    "#     'user_age_level_day_I',\n",
    "#     'user_age_level_day_C',\n",
    "#     'user_gender_id_day_I',\n",
    "#     'user_gender_id_day_C',\n",
    "#     'user_star_level_day_I',\n",
    "#     'user_star_level_day_C',\n",
    "     'item_id_day_I',\n",
    "     'item_id_day_C',\n",
    "     'item_brand_id_day_I',\n",
    "     'item_brand_id_day_C',\n",
    "#     'item_city_id_day_I',\n",
    "#     'item_city_id_day_C',\n",
    "     'category2_label_day_I',\n",
    "     'category2_label_day_C',\n",
    "#     'item_price_level_day_I',\n",
    "#     'item_price_level_day_C',\n",
    "#     'item_sales_level_day_I',\n",
    "#     'item_sales_level_day_C',\n",
    "#     'item_collected_level_day_I',\n",
    "#     'item_collected_level_day_C',\n",
    "#     'item_pv_level_day_I',\n",
    "#     'item_pv_level_day_C',\n",
    "#     'context_page_id_day_I',\n",
    "#     'context_page_id_day_C',\n",
    "     'shop_id_day_I',\n",
    "     'shop_id_day_C',\n",
    "#     'shop_review_num_level_day_I',\n",
    "#     'shop_review_num_level_day_C',\n",
    "#     'shop_star_level_day_I',\n",
    "#     'shop_star_level_day_C',\n",
    "\n",
    "    #  2_5处理后的特征\n",
    "    #  生成历史交叉点击率，前一天的点击次数，前一天的购买次数，只保留ctr\n",
    "    #    ['user_gender_id', 'user_age_level', 'user_occupation_id']\n",
    "    #    ['item_id', 'item_brand_id', 'shop_id']    \n",
    "\n",
    "     'user_gender_id_item_id_smooth_CTR',\n",
    "     'user_gender_id_item_brand_id_smooth_CTR',\n",
    "     'user_gender_id_shop_id_smooth_CTR',\n",
    "     'user_gender_id_item_price_level_smooth_CTR',\n",
    "     'user_age_level_item_id_smooth_CTR',\n",
    "     'user_age_level_item_brand_id_smooth_CTR',\n",
    "     'user_age_level_shop_id_smooth_CTR',\n",
    "     'user_age_level_item_price_level_smooth_CTR',\n",
    "     'user_occupation_id_item_id_smooth_CTR',\n",
    "     'user_occupation_id_item_brand_id_smooth_CTR',\n",
    "     'user_occupation_id_shop_id_smooth_CTR',\n",
    "     'user_occupation_id_item_price_level_smooth_CTR',\n",
    "#     'user_star_level_item_id_smooth_CTR',\n",
    "#     'user_star_level_item_brand_id_smooth_CTR',\n",
    "#     'user_star_level_shop_id_smooth_CTR',\n",
    "     'user_star_level_item_price_level_smooth_CTR',\n",
    "\n",
    "    \n",
    "    #  2_6处理后的特征\n",
    "    #  分别groupby['shop_id', 'item_id', 'item_brand_id', 'item_price_level']\n",
    "    #    计算item在['user_gender_id', 'user_age_level', 'user_occupation_id', 'user_star_level']几个属性下的点击量\n",
    "     'shop_id_user_gender_id_click_rate',\n",
    "     'shop_id_user_age_level_click_rate',\n",
    "     'shop_id_user_occupation_id_click_rate',\n",
    "#     'shop_id_user_star_level_click_rate',\n",
    "     'item_id_user_gender_id_click_rate',\n",
    "     'item_id_user_age_level_click_rate',\n",
    "     'item_id_user_occupation_id_click_rate',\n",
    "#     'item_id_user_star_level_click_rate',\n",
    "     'item_brand_id_user_gender_id_click_rate',\n",
    "     'item_brand_id_user_age_level_click_rate',\n",
    "     'item_brand_id_user_occupation_id_click_rate',\n",
    "#     'item_brand_id_user_star_level_click_rate',\n",
    "     'item_price_level_user_gender_id_click_rate',\n",
    "     'item_price_level_user_age_level_click_rate',\n",
    "     'item_price_level_user_occupation_id_click_rate',\n",
    "     'item_price_level_user_star_level_click_rate',\n",
    "    \n",
    "    #  2_7处理后的特征\n",
    "    #  计算每天的点击量\n",
    "    #     ['user_id', 'user_occupation_id', 'user_age_level', 'user_gender_id', 'user_star_level',\n",
    "    #      'item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level',\n",
    "    #      'item_collected_level', 'item_pv_level',\n",
    "    #      'context_page_id',\n",
    "    #      'shop_id', 'shop_review_num_level', 'shop_star_level',]\n",
    "     'user_id_click_day',\n",
    "     'user_occupation_id_click_day',\n",
    "     'user_age_level_click_day',\n",
    "     'user_gender_id_click_day',\n",
    "     'user_star_level_click_day',\n",
    "     'item_id_click_day',\n",
    "     'item_brand_id_click_day',\n",
    "#     'item_city_id_click_day',\n",
    "     'category2_label_click_day',\n",
    "     'item_price_level_click_day',\n",
    "     'item_sales_level_click_day',\n",
    "     'item_collected_level_click_day',\n",
    "#     'item_pv_level_click_day',\n",
    "     'context_page_id_click_day',\n",
    "     'shop_id_click_day',\n",
    "#     'shop_review_num_level_click_day',\n",
    "#     'shop_star_level_click_day',\n",
    "    #  2_7处理后的特征\n",
    "    #  计算每天每小时的点击量\n",
    "    #     ['user_id', 'user_occupation_id', 'user_age_level', 'user_gender_id', 'user_star_level',\n",
    "    #      'item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level',\n",
    "    #      'item_collected_level', 'item_pv_level',\n",
    "    #      'context_page_id',\n",
    "    #      'shop_id', 'shop_review_num_level', 'shop_star_level',]\n",
    "     'user_id_click_hour_x',\n",
    "     'user_occupation_id_click_hour_x',\n",
    "     'user_age_level_click_hour_x',\n",
    "     'user_gender_id_click_hour_x',\n",
    "     'user_star_level_click_hour_x',\n",
    "     'item_id_click_hour_x',\n",
    "     'item_brand_id_click_hour_x',\n",
    "#     'item_city_id_click_hour_x',\n",
    "     'category2_label_click_hour_x',\n",
    "     'item_price_level_click_hour_x',\n",
    "     'item_sales_level_click_hour_x',\n",
    "     'item_collected_level_click_hour_x',\n",
    "#     'item_pv_level_click_hour_x',\n",
    "#     'context_page_id_click_hour_x',\n",
    "     'shop_id_click_hour_x',\n",
    "#     'shop_review_num_level_click_hour_x',\n",
    "#     'shop_star_level_click_hour_x',\n",
    "    #  2_7处理后的特征\n",
    "    #  计算每小时的点击量\n",
    "    #     ['user_id', 'user_occupation_id', 'user_age_level', 'user_gender_id', 'user_star_level',\n",
    "    #      'item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level',\n",
    "    #      'item_collected_level', 'item_pv_level',\n",
    "    #      'context_page_id',\n",
    "    #      'shop_id', 'shop_review_num_level', 'shop_star_level',]\n",
    "     'user_id_click_hour_y',\n",
    "     'user_occupation_id_click_hour_y',\n",
    "     'user_age_level_click_hour_y',\n",
    "     'user_gender_id_click_hour_y',\n",
    "#     'user_star_level_click_hour_y',\n",
    "     'item_id_click_hour_y',\n",
    "     'item_brand_id_click_hour_y',\n",
    "#     'item_city_id_click_hour_y',\n",
    "     'category2_label_click_hour_y',\n",
    "#     'item_price_level_click_hour_y',\n",
    "#     'item_sales_level_click_hour_y',\n",
    "#     'item_collected_level_click_hour_y',\n",
    "#     'item_pv_level_click_hour_y',\n",
    "#     'context_page_id_click_hour_y',\n",
    "     'shop_id_click_hour_y',\n",
    "#     'shop_review_num_level_click_hour_y',\n",
    "#     'shop_star_level_click_hour_y'\n",
    "]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.674789\tval-logloss:0.674734\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 200 rounds.\n",
      "[50]\ttrain-logloss:0.238424\tval-logloss:0.236086\n",
      "[100]\ttrain-logloss:0.128134\tval-logloss:0.124244\n",
      "[150]\ttrain-logloss:0.096399\tval-logloss:0.091686\n",
      "[200]\ttrain-logloss:0.087346\tval-logloss:0.082471\n",
      "[250]\ttrain-logloss:0.084415\tval-logloss:0.079883\n",
      "[300]\ttrain-logloss:0.082987\tval-logloss:0.078975\n",
      "[350]\ttrain-logloss:0.082004\tval-logloss:0.078608\n",
      "[400]\ttrain-logloss:0.081177\tval-logloss:0.078427\n",
      "[450]\ttrain-logloss:0.080461\tval-logloss:0.078311\n",
      "[499]\ttrain-logloss:0.079816\tval-logloss:0.078245\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-028ffe812f3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m                   verbose_eval=50)\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mloss_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predicted_score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "train_data = all_data[(all_data.day >= 19) & (all_data.day <= 23)]\n",
    "test_data = all_data[all_data.day == 24]\n",
    "\n",
    "dtrain = xgb.DMatrix(train_data[features], train_data[target])\n",
    "dtest = xgb.DMatrix(test_data[features], test_data[target])\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'val')]\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 2000,\n",
    "    'max_depth': 5,\n",
    "    'eta': 0.02,\n",
    "    'eval_metric': 'logloss',\n",
    "    'objective': 'binary:logistic',\n",
    "    'subsample': 1.0,\n",
    "    'colsample_bytree': 0.7,\n",
    "#     'random_state': 1123,\n",
    "#     'min_child_weight': 10\n",
    "    #'scale_pos_weight':0.5\n",
    "}\n",
    "\n",
    "xgb_a = xgb.train(params, dtrain,\n",
    "                  num_boost_round=500,\n",
    "                  early_stopping_rounds=200,\n",
    "                  evals=watchlist,\n",
    "                  verbose_eval=50)\n",
    "\n",
    "loss_train = log_loss(train_data[target], xgb_a.predict_proba(train_data[features]))\n",
    "loss_test = log_loss(test_data[target], xgb_a.predict_proba(test_data[features]))\n",
    "test_data['predicted_score'] = xgb_a.predict_proba(test_data[features])[:, 1]\n",
    "test_data[['instance_id', 'predicted_score']].to_csv(\n",
    "    '25_226_xgboost.txt', index=False, sep=' ')\n",
    "\n",
    "loss_train, loss_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "train_data = all_data[(all_data.day >= 19) & (all_data.day <= 23)]\n",
    "test_data = all_data[all_data.day == 24]\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(objective='binary',\n",
    "\n",
    "                             n_estimators=2000,\n",
    "                             learning_rate=0.02,\n",
    "\n",
    "                             max_depth=4,\n",
    "                             num_leaves=15,\n",
    "                             min_child_samples=70,\n",
    "                             min_child_weight=1e-3,\n",
    "\n",
    "                             colsample_bytree=0.9,\n",
    "                             subsample=0.7,\n",
    "                             subsample_freq=1,\n",
    "\n",
    "                             reg_lambda=12,\n",
    "                             min_split_gain=0.,\n",
    "\n",
    "                             n_jobs=-1,\n",
    "                             silent=False\n",
    "                             )\n",
    "\n",
    "\n",
    "#cate_features = ['user_gender_id', 'user_occupation_id', 'hour']\n",
    "\n",
    "lgb_clf.fit(train_data[features], train_data[target],\n",
    "            eval_set=[(test_data[features], test_data[target])],\n",
    "            early_stopping_rounds=200,\n",
    "            feature_name=features,\n",
    "#             categorical_feature=cate_features,\n",
    "            verbose=50,\n",
    "            )\n",
    "\n",
    "loss_train = log_loss(train_data[target],lgb_clf.predict_proba(train_data[features]))\n",
    "loss_test = log_loss(test_data[target], lgb_clf.predict_proba(test_data[features]))\n",
    "\n",
    "\n",
    "loss_train, loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "train_data = all_data[(all_data.day >= 19) & (all_data.day <= 23)]\n",
    "test_data = all_data[all_data.day == 24]\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(objective='binary',\n",
    "\n",
    "                             n_estimators=2000,\n",
    "                             learning_rate=0.02,\n",
    "\n",
    "                             max_depth=4,\n",
    "                             num_leaves=15,\n",
    "                             min_child_samples=100,\n",
    "                             min_child_weight=1e-3,\n",
    "\n",
    "                             colsample_bytree=1.0,\n",
    "                             subsample=0.7,\n",
    "                             subsample_freq=1,\n",
    "\n",
    "                             reg_lambda=15,\n",
    "                             min_split_gain=0.,\n",
    "                             \n",
    "                             max_bin=63,\n",
    "\n",
    "                             n_jobs=-1,\n",
    "                             silent=False,\n",
    "                             \n",
    "                             #device='gpu',\n",
    "                             gpu_use_dp=False,\n",
    "                             )\n",
    "\n",
    "lgb_clf.fit(train_data[features], train_data[target],\n",
    "            eval_set=[(test_data[features], test_data[target])],\n",
    "            early_stopping_rounds=200,\n",
    "            feature_name=features,\n",
    "#             categorical_feature=cate_features,\n",
    "            verbose=50,\n",
    "            )\n",
    "\n",
    "loss_train = log_loss(train_data[target],lgb_clf.predict_proba(train_data[features]))\n",
    "loss_test = log_loss(test_data[target], lgb_clf.predict_proba(test_data[features]))\n",
    "\n",
    "test_data['predicted_score'] = lgb_clf.predict_proba(test_data[features])[:, 1]\n",
    "\n",
    "test_data[['instance_id', 'predicted_score']].to_csv(\n",
    "    '25_226.txt', index=False, sep=' ')\n",
    "\n",
    "\n",
    "loss_train, loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "19-22 23  1120 0.0802662 0.078982     950:0.079021      1300:0.079049  \n",
    "\n",
    "19-23 24  1207 0.0794017 0.077929     900:0.07799       1400:0.0779677\n",
    "20-23 24  900  0.0792304 0.078160     750:0.07819       1100:0.0781925\n",
    "21-23 24  768  0.0782709 0.078262     750:0.07827       950:0.0782948\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399850, 472)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07849904319932105"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "train_data = all_data[(all_data.day >= 19) & (all_data.day <= 24)]\n",
    "print(train_data.shape)\n",
    "\n",
    "test_data = all_data[(all_data.day == 25) & (all_data.is_trade == -2)]\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(objective='binary',\n",
    "\n",
    "                             n_estimators=1325,\n",
    "                             learning_rate=0.02,\n",
    "\n",
    "                             max_depth=4,\n",
    "                             num_leaves=15,\n",
    "                             min_child_samples=100,\n",
    "                             min_child_weight=1e-3,\n",
    "\n",
    "                             colsample_bytree=1.0,\n",
    "                             subsample=0.7,\n",
    "                             subsample_freq=1,\n",
    "\n",
    "                             reg_lambda=15,\n",
    "                             min_split_gain=0.,\n",
    "                             \n",
    "                             max_bin=63,\n",
    "\n",
    "                             n_jobs=-1,\n",
    "                             silent=False,\n",
    "                             \n",
    "                             #device='gpu',\n",
    "                             gpu_use_dp=False,\n",
    "                             )\n",
    "\n",
    "                     \n",
    "lgb_clf.fit(train_data[features], train_data[target],feature_name=features)\n",
    "\n",
    "loss_train = log_loss(train_data[target], lgb_clf.predict_proba(train_data[features]))\n",
    "\n",
    "test_data['predicted_score'] = lgb_clf.predict_proba(test_data[features])[:, 1]\n",
    "\n",
    "test_data[['instance_id', 'predicted_score']].to_csv(\n",
    "    '20180421_1325.txt', index=False, sep=' ')\n",
    "\n",
    "loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(bst.feature_importance())\n",
    "importance.columns = ['importance_20']\n",
    "features = pd.DataFrame(features)\n",
    "features.columns = ['features_20']\n",
    "pd.set_option('max_rows',500)\n",
    "merge = features.join(importance)\n",
    "merge = merge.sort_values(by=['importance_20'], ascending=False).reset_index()\n",
    "merge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
