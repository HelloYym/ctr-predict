{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 时间戳转字符串\n",
    "def timestamp_datetime(value):\n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "    value = time.localtime(value)\n",
    "    dt = time.strftime(format, value)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_feats = ['item_price_level', 'item_sales_level', 'item_collected_level', 'item_pv_level', 'user_age_level',\n",
    "                 'user_star_level', 'shop_review_num_level',\n",
    "                 'shop_review_positive_rate', 'shop_star_level', 'shop_score_service', 'shop_score_delivery', 'shop_score_description',\n",
    "                 'hour', 'day',\n",
    "                 'user_query_day', 'user_query_day_hour',\n",
    "                 'item_CTR', 'shop_CTR', \n",
    "                 ]\n",
    "\n",
    "nominal_feats = ['item_id', 'user_id', 'shop_id', 'item_brand_id',\n",
    "                 'item_city_id', 'user_gender_id', 'user_occupation_id', 'context_page_id']\n",
    "\n",
    "features = numeric_feats + nominal_feats\n",
    "\n",
    "target = 'is_trade'\n",
    "\n",
    "def extract_date(data):\n",
    "    data['time'] = data.context_timestamp.apply(timestamp_datetime)\n",
    "    data['day'] = data.time.apply(lambda x: int(x[8:10]))\n",
    "    data['hour'] = data.time.apply(lambda x: int(x[11:13]))\n",
    "    del data['time']\n",
    "    return data\n",
    "\n",
    "def extract_ctr(data, feature, alias):\n",
    "    '''统计给定数据的转化率\n",
    "    \n",
    "    '''\n",
    "    query_cnt = data.groupby([feature]).size().reset_index().rename(columns={0: 'query_cnt'})\n",
    "    conversion_cnt = data[data['is_trade'] == 1].groupby([feature]).size().reset_index().rename(columns={0: 'conversion_cnt'})\n",
    "    ctr = pd.merge(query_cnt, conversion_cnt, how='left', on=[feature])\n",
    "    ctr[['conversion_cnt']] = ctr[['conversion_cnt']].fillna(0)\n",
    "    ctr[alias] = ctr['conversion_cnt'] / ctr['query_cnt']\n",
    "    del ctr['query_cnt']\n",
    "    del ctr['conversion_cnt']\n",
    "    return ctr\n",
    "\n",
    "def extract_history_ctr(data, feature, alias):\n",
    "    '''统计每一天之前的历史转化率\n",
    "    \n",
    "    '''\n",
    "    history_ctr = pd.DataFrame(columns = [feature, alias, 'day'])\n",
    "    \n",
    "    for day in range(18, 26):\n",
    "        # 每一天之前的历史数据\n",
    "        history_data = data[data['day'] < day]\n",
    "        ctr = extract_ctr(history_data, feature, alias)        \n",
    "    \n",
    "        # 添加date字段，方便merge\n",
    "        ctr['day'] = day\n",
    "        history_ctr = history_ctr.append(ctr)\n",
    "        \n",
    "    return history_ctr\n",
    "    \n",
    "\n",
    "def extract_manual_features(data):\n",
    "    \n",
    "    user_query_day = data.groupby(['user_id', 'day']).size(\n",
    "    ).reset_index().rename(columns={0: 'user_query_day'})\n",
    "    data = pd.merge(data, user_query_day, how='left',\n",
    "                    on=['user_id', 'day'])\n",
    "\n",
    "    user_query_day_hour = data.groupby(['user_id', 'day', 'hour']).size(\n",
    "    ).reset_index().rename(columns={0: 'user_query_day_hour'})\n",
    "    data = pd.merge(data, user_query_day_hour, how='left',\n",
    "                    on=['user_id', 'day', 'hour'])\n",
    "    \n",
    "    history_item_ctr = extract_history_ctr(data, 'item_id', 'item_CTR')\n",
    "    data = pd.merge(data, history_item_ctr, how='left', on=['item_id', 'day'])\n",
    "    data[['item_CTR']] = data[['item_CTR']].fillna(-1)\n",
    "        \n",
    "    history_shop_ctr = extract_history_ctr(data, 'shop_id', 'shop_CTR')\n",
    "    data = pd.merge(data, history_shop_ctr, how='left', on=['shop_id', 'day'])\n",
    "    data[['shop_CTR']] = data[['shop_CTR']].fillna(-1)\n",
    "    \n",
    "    feature_with_CTR = ['shop_id', 'item_id', 'day']\n",
    "    data[feature_with_CTR] = data[feature_with_CTR].astype(np.int64)\n",
    "    \n",
    "#     data = pd.get_dummies(data, dummy_na=True, columns=['user_gender_id', 'user_occupation_id', 'context_page_id'])\n",
    "\n",
    "    \n",
    "#     data = data.replace(to_replace=[-1], value=np.NaN)\n",
    "#     data[numeric_feats] = data[numeric_feats].fillna(data.mean())\n",
    "#     data[numeric_feats] = data[numeric_feats].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取训练样本并转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ff4cd13df431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnum_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_manual_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d83919221d21>\u001b[0m in \u001b[0;36mextract_manual_features\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'day'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     user_query_day = data.groupby(['user_id', 'day']).size(\n",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3075\u001b[0m         if (name in self._internal_names_set or name in self._metadata or\n\u001b[1;32m   3076\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 3077\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3078\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"round1_ijcai_18_train_20180301.txt\", sep=' ')\n",
    "df_test = pd.read_csv(\"round1_ijcai_18_test_a_20180301.txt\", sep=' ')\n",
    "\n",
    "df_train.drop_duplicates(inplace=True)\n",
    "df_train = extract_date(df_train)\n",
    "df_test = extract_date(df_test)\n",
    "\n",
    "num_train = df_train.shape[0]\n",
    "all_data = pd.concat([df_train, df_test])\n",
    "all_data = extract_manual_features(all_data)\n",
    "df_train = all_data[:num_train]\n",
    "df_test = all_data[num_train:]\n",
    "del df_test['is_trade']\n",
    "\n",
    "\n",
    "# 根据日期，取24号为验证集\n",
    "train_data = df_train.loc[df_train.day < df_train['day'].max()]\n",
    "val_data = df_train.loc[df_train.day == df_train['day'].max()]\n",
    "\n",
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_gender_id</th>\n",
       "      <th>page_CTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.012866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.018420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.021124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.018842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_gender_id  page_CTR\n",
       "0              -1  0.012866\n",
       "1               0  0.018420\n",
       "2               1  0.021124\n",
       "3               2  0.018842"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_ctr(df_train, feature='user_gender_id', alias='page_CTR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['context_id', 'context_page_id', 'context_timestamp', 'day', 'hour',\n",
       "       'instance_id', 'is_trade', 'item_brand_id', 'item_category_list',\n",
       "       'item_city_id', 'item_collected_level', 'item_id', 'item_price_level',\n",
       "       'item_property_list', 'item_pv_level', 'item_sales_level',\n",
       "       'predict_category_property', 'shop_id', 'shop_review_num_level',\n",
       "       'shop_review_positive_rate', 'shop_score_delivery',\n",
       "       'shop_score_description', 'shop_score_service', 'shop_star_level',\n",
       "       'user_age_level', 'user_gender_id', 'user_id', 'user_occupation_id',\n",
       "       'user_star_level', 'user_query_day', 'user_query_day_hour', 'item_CTR',\n",
       "       'shop_CTR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_feats = ['item_price_level', 'item_sales_level', 'item_collected_level', 'item_pv_level', 'user_age_level',\n",
    "                 'user_star_level', 'shop_review_num_level',\n",
    "                 'shop_review_positive_rate', 'shop_star_level', 'shop_score_service', 'shop_score_delivery', 'shop_score_description',\n",
    "                 'hour', 'day',\n",
    "                 'user_query_day', 'user_query_day_hour',\n",
    "                 'item_CTR', 'shop_CTR', \n",
    "                 ]\n",
    "\n",
    "nominal_feats = ['item_id', 'user_id', 'shop_id', 'item_brand_id',\n",
    "                 'item_city_id', 'user_gender_id', 'user_occupation_id', 'context_page_id']\n",
    "\n",
    "features = numeric_feats + nominal_feats\n",
    "\n",
    "target = 'is_trade'\n",
    "\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user02/miniconda3/envs/gluon/lib/python3.6/site-packages/lightgbm/basic.py:1038: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['user_gender_id']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.088003286862289073, 0.081456150703436425)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "clf = lgb.LGBMClassifier(max_depth=4, n_estimators=100, n_jobs=-1)\n",
    "\n",
    "clf.fit(train_data[features], train_data[target], feature_name=features, categorical_feature=['user_gender_id'])\n",
    "\n",
    "loss_train = log_loss(train_data[target], clf.predict_proba(train_data[features]))\n",
    "loss_val = log_loss(val_data[target], clf.predict_proba(val_data[features]))\n",
    "\n",
    "loss_train, loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练和测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.088690767298507736, 0.081663202197175475)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, precision_score, recall_score, accuracy_score, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty=\"l2\", solver='liblinear',\n",
    "                        max_iter=1000, verbose=1)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbdt = GradientBoostingClassifier(n_estimators=100, max_features='auto')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=5, bootstrap=True, max_features='auto')\n",
    "\n",
    "clf = gbdt\n",
    "clf.fit(train_data[features], train_data[target])\n",
    "\n",
    "loss_train = log_loss(train_data[target], clf.predict_proba(train_data[features]))\n",
    "predicted = clf.predict_proba(val_data[features])\n",
    "loss_val = log_loss(val_data[target], predicted)\n",
    "\n",
    "loss_train, loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提交测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user02/miniconda3/envs/gluon/lib/python3.6/site-packages/lightgbm/basic.py:1038: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['user_gender_id']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/home/user02/miniconda3/envs/gluon/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.087222402067231086"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf = lgb.LGBMClassifier(max_depth=4, n_estimators=100, n_jobs=-1)\n",
    "clf.fit(df_train[features], df_train[target], feature_name=features, categorical_feature=['user_gender_id'])\n",
    "\n",
    "loss_train = log_loss(df_train[target], clf.predict_proba(df_train[features]))\n",
    "\n",
    "df_test['predicted_score'] = clf.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "df_test[['instance_id', 'predicted_score']].to_csv(\n",
    "    '20180325.txt', index=False, sep=' ')\n",
    "\n",
    "loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
